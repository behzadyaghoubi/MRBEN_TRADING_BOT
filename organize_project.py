import os
import shutil
import hashlib
from datetime import datetime

BASE_DIR = os.getcwd()
LOG_FILE = os.path.join(BASE_DIR, "organize_log.txt")

# Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ùˆ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§
folder_map = {
    'src': ['main.py', 'main_runner.py', 'app.py', 'settings.json'],
    'data': ['.csv', '.npy', 'XAUUSD_PRO'],
    'models': ['.h5', '.save', '.joblib'],
    'strategies': ['strategy', 'book_', 'signal_generator', 'lstm_trading_model', 'ml_signal_filter'],
    'tools': ['download_', 'calculate_', 'fix_', 'export_', 'prepare_', 'feature_', 'plot_', 'check_', 'generate_'],
    'tests': ['test_', 'run_tests'],
    'dashboards': ['dashboard', 'mrben_dashboard', 'web'],
    'backtests': ['backtest', 'optimize_', 'sl_tp', 'train_'],
}

# Ù…Ø³ÛŒØ± Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡ Ø¨Ú©â€ŒØ¢Ù¾
BACKUP_DIR = os.path.join(BASE_DIR, "backup_duplicates")
os.makedirs(BACKUP_DIR, exist_ok=True)

# Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
for folder in folder_map:
    os.makedirs(os.path.join(BASE_DIR, folder), exist_ok=True)

# ØªØ§Ø¨Ø¹ Ù‡Ø´ ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯Ù†
def hash_file(filepath):
    hasher = hashlib.md5()
    with open(filepath, 'rb') as f:
        buf = f.read()
        hasher.update(buf)
    return hasher.hexdigest()

# ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‡Ø´
hashes_seen = {}

# Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Ù„Ø§Ú¯
with open(LOG_FILE, 'w', encoding='utf-8') as log:
    log.write(f"==== MR BEN PROJECT ORGANIZATION LOG ====\n{datetime.now()}\n\n")

    for file in os.listdir(BASE_DIR):
        file_path = os.path.join(BASE_DIR, file)
        if os.path.isfile(file_path) and file != os.path.basename(__file__) and file != os.path.basename(LOG_FILE):
            moved = False

            # ØªØ´Ø®ÛŒØµ Ù‡Ø´ ÙØ§ÛŒÙ„
            file_hash = hash_file(file_path)
            if file_hash in hashes_seen:
                backup_name = f"{file}_DUPLICATE_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                backup_path = os.path.join(BACKUP_DIR, backup_name)
                shutil.move(file_path, backup_path)
                log.write(f"[DUPLICATE REMOVED] {file} âœ backup_duplicates/\n")
                continue
            else:
                hashes_seen[file_hash] = file

            for folder, keywords in folder_map.items():
                if any(keyword in file for keyword in keywords):
                    dest_path = os.path.join(BASE_DIR, folder, file)

                    # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ù‚Ø¨Ù„Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡ØŒ Ø¨Ú©â€ŒØ¢Ù¾ Ø¨Ú¯ÛŒØ±
                    if os.path.exists(dest_path):
                        backup_file = f"{file}_BACKUP_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                        backup_path = os.path.join(BACKUP_DIR, backup_file)
                        shutil.move(dest_path, backup_path)
                        log.write(f"[BACKUP] Existing {file} âœ backup_duplicates/\n")

                    shutil.move(file_path, dest_path)
                    log.write(f"[MOVED] {file} âœ {folder}/\n")
                    moved = True
                    break

            if not moved:
                log.write(f"[SKIPPED] {file} (No match found)\n")

    log.write("\nâœ… Organization complete.\n")

print("ğŸ¯ Project has been organized successfully! Check 'organize_log.txt' for details.")